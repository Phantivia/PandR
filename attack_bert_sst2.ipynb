{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "##print(\"pakages imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MyBertSelfAttention_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "from torch import nn\n",
    "GRAPH =[]\n",
    "from torch.nn import Softmax\n",
    "class MyBertSelfAttention_detect(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
    "            raise ValueError(\n",
    "                \"The hidden size (%d) is not a multiple of the number of attention \"\n",
    "                \"heads (%d)\" % (config.hidden_size, config.num_attention_heads)\n",
    "            )\n",
    "\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.config = config\n",
    "        \n",
    "        self.perturb_on = False\n",
    "        self.perturb = None\n",
    "        self.sofm = Softmax(dim = 0)\n",
    "        \n",
    "        self.flag = False\n",
    "        self.count = 0\n",
    "#         self.hidden_temp = None\n",
    "\n",
    "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
    "        self.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")\n",
    "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
    "            self.max_position_embeddings = config.max_position_embeddings\n",
    "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
    "\n",
    "        self.is_decoder = config.is_decoder\n",
    "    #modified\n",
    "    \n",
    "    def p_init(self, input_length, start_from = None):\n",
    "        SQRT_NUMEL = (input_length * self.config.hidden_size) ** 0.5\n",
    "        self.perturb = torch.zeros((BATCH_SIZE, input_length, self.config.hidden_size), device = torch.device('cuda')).uniform_(-INIT_MAG, INIT_MAG)/SQRT_NUMEL\n",
    "        \n",
    "        self.perturb[:, 0, : ] = 0.0\n",
    "        self.perturb[:, -1, :] = 0.0\n",
    "        \n",
    "        if start_from is not None:\n",
    "            self.perturb = (self.perturb + start_from).detach()\n",
    "            \n",
    "        self.perturb.requires_grad_()\n",
    "        \n",
    "    def p_accu(self, loss, adv_lr, input_length = 5):\n",
    "        grad = torch.autograd.grad(loss, self.perturb)[0]\n",
    "\n",
    "        grad[:, 0, :] = 0.0\n",
    "        grad[:, -1, :] = 0.0\n",
    "        \n",
    "        grad = (adv_lr * grad/grad.norm()).detach()\n",
    "        \n",
    "        self.perturb = (self.perturb + grad).detach()\n",
    "\n",
    "        self.perturb.grad = None\n",
    "        self.perturb.requires_grad_()\n",
    "        \n",
    "    ##here\n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        past_key_value=None,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "        if self.perturb is not None:\n",
    "            hidden_states = hidden_states + self.perturb\n",
    "        \n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        \n",
    "        \n",
    "        # If this is instantiated as a cross-attention module, the keys\n",
    "        # and values come from an encoder; the attention mask needs to be\n",
    "        # such that the encoder's padding tokens are not attended to.\n",
    "        is_cross_attention = encoder_hidden_states is not None\n",
    "\n",
    "        if is_cross_attention and past_key_value is not None:\n",
    "            # reuse k,v, cross_attentions\n",
    "            key_layer = past_key_value[0]\n",
    "            value_layer = past_key_value[1]\n",
    "            attention_mask = encoder_attention_mask\n",
    "        elif is_cross_attention:\n",
    "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
    "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
    "            attention_mask = encoder_attention_mask\n",
    "        elif past_key_value is not None:\n",
    "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
    "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
    "            key_layer = torch.cat([past_key_value[0], key_layer], dim=2)\n",
    "            value_layer = torch.cat([past_key_value[1], value_layer], dim=2)\n",
    "        else:\n",
    "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
    "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "\n",
    "        if self.is_decoder:\n",
    "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
    "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
    "            # key/value_states (first \"if\" case)\n",
    "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
    "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
    "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
    "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
    "            past_key_value = (key_layer, value_layer)\n",
    "\n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "\n",
    "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
    "            seq_length = hidden_states.size()[1]\n",
    "            position_ids_l = torch.arange(seq_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
    "            position_ids_r = torch.arange(seq_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
    "            distance = position_ids_l - position_ids_r\n",
    "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
    "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
    "\n",
    "            if self.position_embedding_type == \"relative_key\":\n",
    "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
    "                attention_scores = attention_scores + relative_position_scores\n",
    "            elif self.position_embedding_type == \"relative_key_query\":\n",
    "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
    "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
    "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
    "\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "            \n",
    "        if attention_mask is not None:\n",
    "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
    "            attention_scores = attention_scores + attention_mask\n",
    "\n",
    "        # Normalize the attention scores to probabilities.\n",
    "        #modified\n",
    "\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "\n",
    "\n",
    "        # This is actually dropping out entire tokens to attend to, which might\n",
    "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        # Mask heads if we want to\n",
    "        if head_mask is not None:\n",
    "            attention_probs = attention_probs * head_mask\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "\n",
    "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
    "\n",
    "        if self.is_decoder:\n",
    "            outputs = outputs + (past_key_value,)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLUE_TASKS = [\"cola\", \"mnli\", \"mnli-mm\", \"mrpc\", \"qnli\", \"qqp\", \"rte\", \"sst2\", \"stsb\", \"wnli\"]\n",
    "task = 'sst2'\n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "model_state = None\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c315a7cdf642c3a674788591351859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=68.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118336e9885440ee916dfa04ce5969d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52639b74938149c5ad1be841a2f813e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "import datasets\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "import math\n",
    "\n",
    "from datasets import load_dataset, load_metric\n",
    "import datasets\n",
    "actual_task = \"mnli\" if task == \"mnli-mm\" else task\n",
    "dataset = datasets.DatasetDict.load_from_disk(\"glue/\" + actual_task) if task != \"imdb\" else datasets.load_from_disk('imdb')\n",
    "\n",
    "if task == \"imdb\":\n",
    "    del dataset['unsupervised']\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, BertForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "task_to_keys = {  \n",
    "            \"sst2\": (\"sentence\", None),\n",
    "            \"imdb\": (\"text\", None)\n",
    "        }\n",
    "\n",
    "sentence1_key, sentence2_key = task_to_keys[task]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    if sentence2_key is None:\n",
    "        return tokenizer(examples[sentence1_key], truncation=True)\n",
    "    return tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=True)\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
    "encoded_dataset.set_format(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained(model_checkpoint, num_labels = num_labels, mirror = \"bfsu\")\n",
    "model.load_state_dict(torch.load(\"SST2-fullfinetuned-bert-8848.pth\"))\n",
    "torch.save(model.state_dict(),\"temp_state.pth\")\n",
    "\n",
    "for i in model.bert.encoder.layer:\n",
    "    p_layer = MyBertSelfAttention_detect(model.config)\n",
    "    i.attention.self = p_layer\n",
    "\n",
    "model.load_state_dict(torch.load('temp_state.pth'))\n",
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertOnlyMLMHead(\n",
       "  (predictions): BertLMPredictionHead(\n",
       "    (transform): BertPredictionHeadTransform(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "mlm_model = AutoModelForMaskedLM.from_pretrained(model_checkpoint, mirror = \"bfsu\")\n",
    "probe_layer = mlm_model.cls\n",
    "probe_layer.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_model = BertForSequenceClassification(model.config)\n",
    "victim_model.load_state_dict(torch.load(\"SST2-fullfinetuned-bert-8848.pth\"))\n",
    "if torch.cuda.is_available():\n",
    "    victim_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "class USE:\n",
    "    def __init__(self):\n",
    "        self.embed = hub.load(\"use\")\n",
    "\n",
    "    def count_use(self, sentence1, sentence2):\n",
    "        embeddings = self.embed([sentence1, sentence2])\n",
    "\n",
    "        vector1 = tf.reshape(embeddings[0], [512, 1])\n",
    "        vector2 = tf.reshape(embeddings[1], [512, 1])\n",
    "\n",
    "        return tf.matmul(vector1, vector2, transpose_a=True).numpy()[0][0]\n",
    "use = USE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "class Prober():\n",
    "    \n",
    "    def __init__(self, tokenizer, probe_layer, victim_model):\n",
    "        self.celoss = CrossEntropyLoss()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.probe_layer = probe_layer\n",
    "        self.victim = victim_model\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.probe_layer.cuda()\n",
    "            \n",
    "    def decode(self, hidden, origin_ids = None):\n",
    "        probe = self.probe_layer(hidden)\n",
    "        \n",
    "        _probe = probe.detach()\n",
    "        _probe[:, :,0:1000] = 0.0\n",
    "        \n",
    "        \n",
    "        reconstruction_ids = torch.topk(_probe, 1, -1)[1].squeeze(-1)\n",
    "        \n",
    "        reconstruction_ids[:, 0] = 101\n",
    "        reconstruction_ids[:,-1] = 102\n",
    "        \n",
    "        if origin_ids is None:\n",
    "            return reconstruction_ids\n",
    "        \n",
    "        origin_ids = origin_ids[:, 1:-1].long().cuda()\n",
    "        probe = probe[:, 1:-1, :]\n",
    "\n",
    "        \n",
    "        decode_loss = self.celoss(probe.reshape(-1, tokenizer.vocab_size), origin_ids.reshape(-1))\n",
    "\n",
    "        return decode_loss, reconstruction_ids\n",
    "        \n",
    "    \n",
    "    def attack(self, ids, answer_label):\n",
    "        \n",
    "        ids = ids.unsqueeze(0).cuda()\n",
    "        attention_mask = (torch.zeros(ids.shape) + 1).long().cuda()\n",
    "        \n",
    "        output = self.victim(input_ids = ids, attention_mask = attention_mask, labels = answer_label)\n",
    "        logits = output[1]\n",
    "\n",
    "        adv_answer = logits.argmax(dim = 1)\n",
    "        \n",
    "        ids = ids[:, 1:-1]\n",
    "        reconstruction_tokens = self.tokenizer.batch_decode(ids)\n",
    "        reconstruction_sentence = self.tokenizer.convert_tokens_to_string(reconstruction_tokens)\n",
    "#         print(reconstruction_sentence)\n",
    "\n",
    "#         print(adv_answer,answer_label, \"LOGITS: \", logits )\n",
    "        reconstruction_sentence = None\n",
    "        \n",
    "        \n",
    "        if not adv_answer.equal(answer_label):\n",
    "            #print(\"CALL\")\n",
    "            reconstruction_tokens = self.tokenizer.batch_decode(ids)\n",
    "            reconstruction_sentence = self.tokenizer.convert_tokens_to_string(reconstruction_tokens)\n",
    "            \n",
    "        return reconstruction_sentence\n",
    "    \n",
    "prober = Prober(tokenizer, probe_layer, victim_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def cal_metric(s1, s2):\n",
    "    _use = use.count_use(s1,s2)\n",
    "    return _use,0,0\n",
    "\n",
    "def attack_step(dataset = None, encoded_dataset = None, index = 0, \n",
    "                adv_lr = 3e-2, adv_steps = 3, start_layer = 0, prober = None, \n",
    "                scheduler = None, SEED = 114514):\n",
    "    \n",
    "    encoded_dataset.set_format(\"numpy\")\n",
    "    \n",
    "    def model_forward(model, input_ids, attention_mask, labels):\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask, labels = labels, output_hidden_states = True)\n",
    "        loss = output[0]\n",
    "        hidden = output[2][HIDDEN_INDEX]\n",
    "        logits = output[1]\n",
    "        return loss,logits,hidden\n",
    "    \n",
    "    def random_cover(ids):\n",
    "        import random \n",
    "        rindex = random.randint(1, input_length- 2)\n",
    "        ids[:, rindex] = 103\n",
    "        return ids\n",
    "    \n",
    "    \n",
    "\n",
    "    ori_sentence = dataset['validation'][index]['sentence']\n",
    "    input_ids = torch.tensor(encoded_dataset['validation']['input_ids'][index]).unsqueeze(0)\n",
    "    attention_mask = torch.tensor(encoded_dataset['validation']['attention_mask'][index]).unsqueeze(0)\n",
    "    label = torch.tensor(encoded_dataset['validation']['label'][index]).unsqueeze(0).cuda()\n",
    "    \n",
    "    #print(\"LABEL\", label)\n",
    "    correct_test = prober.attack(input_ids[0], label)\n",
    "    #print(correct_test)\n",
    "    if correct_test is not None:\n",
    "        return None\n",
    "    \n",
    "    #BATCH SET UP\n",
    "    input_length = len(input_ids[0])\n",
    "    ori_input_ids = torch.tensor(input_ids.tolist() * BATCH_SIZE).cuda()\n",
    "    attention_mask = torch.tensor(attention_mask.tolist() * BATCH_SIZE).cuda()\n",
    "    batch_labels = torch.tensor(label.tolist() * BATCH_SIZE).cuda()\n",
    "    \n",
    "    input_ids = random_cover(ori_input_ids.clone())\n",
    "    \n",
    "    p_layer = model.bert.encoder.layer[start_layer].attention.self\n",
    "    p_layer.perturb = None\n",
    "        \n",
    "    \n",
    "    successed = False\n",
    "    query = 0\n",
    "    pll = 0\n",
    "    I = 0\n",
    "    use = 0\n",
    "    bpstep = 0\n",
    "    rec_token_acc = 0\n",
    "    adv_sentence = None\n",
    "    \n",
    "    id_base = []\n",
    "    id_base.append(input_ids.tolist())\n",
    "\n",
    "    torch.manual_seed(SEED)\n",
    "    origin_loss, origin_logits, origin_hidden = model_forward(model, input_ids=input_ids, attention_mask=attention_mask, labels = batch_labels)\n",
    "    reconstruct_ids = prober.decode(origin_hidden)\n",
    "\n",
    "    rec_token_acc = ((input_ids == reconstruct_ids).sum() / input_ids.numel()).tolist()\n",
    "    \n",
    "    for i in reconstruct_ids:\n",
    "        if not i.tolist() in id_base:\n",
    "            id_base.append(i.tolist())\n",
    "            query += 1\n",
    "            adv_sentence = prober.attack(i, label)\n",
    "            if adv_sentence is not None:\n",
    "                use,I,ppl = cal_metric(ori_sentence, adv_sentence)\n",
    "                #print(\"USE = \", use)\n",
    "                if use > USE_GATE:\n",
    "                    successed = True\n",
    "                    bpstep = -1\n",
    "                    successed = True\n",
    "                    return{\n",
    "                        'successed': successed,\n",
    "                        'query': query,\n",
    "                        'pll': pll,\n",
    "                        'I': I,\n",
    "                        'use': use,\n",
    "                        'bpstep': bpstep,\n",
    "                        'token_acc': rec_token_acc,\n",
    "                        'ori_sentence': ori_sentence,\n",
    "                        'adv_sentence': adv_sentence\n",
    "                    }\n",
    "\n",
    "    torch.manual_seed(SEED)\n",
    "    p_layer.p_init(input_length)\n",
    "    torch.manual_seed(SEED)\n",
    "    loss, logits, hidden = model_forward(model, input_ids=input_ids, attention_mask=attention_mask, labels = batch_labels)\n",
    "    decode_loss, init_ids = prober.decode(hidden, origin_ids = input_ids)\n",
    "    \n",
    "    for i in init_ids:\n",
    "        if not i.tolist() in id_base:\n",
    "            id_base.append(i.tolist())\n",
    "            query += 1\n",
    "            adv_sentence = prober.attack(i, label)\n",
    "            if adv_sentence is not None:\n",
    "                use,I,ppl = cal_metric(ori_sentence, adv_sentence)\n",
    "                if use > USE_GATE:\n",
    "                    successed = True\n",
    "                    bpstep = -1\n",
    "                    successed = True\n",
    "                    return{\n",
    "                        'successed': successed,\n",
    "                        'query': query,\n",
    "                        'pll': pll,\n",
    "                        'I': I,\n",
    "                        'use': use,\n",
    "                        'bpstep': bpstep,\n",
    "                        'token_acc': rec_token_acc,\n",
    "                        'ori_sentence': ori_sentence,\n",
    "                        'adv_sentence': adv_sentence\n",
    "                    }\n",
    "\n",
    "\n",
    "\n",
    "    max_use = 0\n",
    "    \n",
    "    for seg_step in range(SEG_STEP):\n",
    "        lr = adv_lr\n",
    "        for i in (range(adv_steps)):\n",
    "\n",
    "            projected = p_layer.p_accu(loss * LOSS_WEIGHT - decode_loss * DECODE_WEIGHT, lr, input_length = input_length)\n",
    "\n",
    "            torch.manual_seed(SEED)\n",
    "            loss, logits, hidden =  model_forward(model, input_ids=input_ids, attention_mask=attention_mask, labels = batch_labels)\n",
    "            decode_loss, p_ids = prober.decode(hidden, origin_ids = input_ids)\n",
    "\n",
    "            for p_id in p_ids:\n",
    "                if not p_id.tolist() in id_base:\n",
    "                    id_base.append(p_id.tolist())\n",
    "                    query += 1\n",
    "                    adv_sentence = prober.attack(p_id, label)\n",
    "\n",
    "                    if adv_sentence is not None:\n",
    "                        use,I,ppl = cal_metric(ori_sentence, adv_sentence)\n",
    "#                         print(adv_sentence, \" USE = \",use)\n",
    "                        if use> max_use:\n",
    "                            max_use = use\n",
    "                        if use > USE_GATE:\n",
    "                            successed = True\n",
    "                            bpstep = seg_step * adv_steps + i\n",
    "                            successed = True\n",
    "                            return{\n",
    "                                'successed': successed,\n",
    "                                'query': query,\n",
    "                                'pll': pll,\n",
    "                                'I': I,\n",
    "                                'use': use,\n",
    "                                'bpstep': bpstep,\n",
    "                                'token_acc': rec_token_acc,\n",
    "                                'ori_sentence': ori_sentence,\n",
    "                                'adv_sentence': adv_sentence\n",
    "                            }\n",
    "#         print(\"################RESET!####################\", \" D_LOSS = \", (loss-origin_loss).norm(), \"BASED: \", len(id_base), \"Query; \", query)\n",
    "        input_ids = random_cover(ori_input_ids.clone())\n",
    "#         print(input_ids.tolist())\n",
    "        torch.manual_seed(SEED + seg_step)\n",
    "        p_layer.p_init(input_length, start_from = None)\n",
    "        loss, logits, hidden = model_forward(model, input_ids=input_ids, attention_mask=attention_mask, labels = batch_labels)\n",
    "    torch.cuda.empty_cache()\n",
    "    return{\n",
    "        'successed': successed,\n",
    "        'query': query,\n",
    "        'pll': pll,\n",
    "        'I': I,\n",
    "        'use': max_use,\n",
    "        'bpstep': bpstep,\n",
    "        'token_acc': rec_token_acc,\n",
    "        'ori_sentence': ori_sentence,\n",
    "        'adv_sentence': adv_sentence\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/512 [00:00<?, ?it/s]/mistgpu/site-packages/datasets/formatting/formatting.py:163: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(array, copy=False, **self.np_array_kwargs)\n",
      "100%|██████████| 512/512 [15:46:38<00:00, 110.93s/it]   \n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "import seaborn as sb\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "SEG_STEP = 20\n",
    "\n",
    "HIDDEN_INDEX = 6\n",
    "\n",
    "INIT_MAG = 1\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "USE_GATE = 0.85\n",
    "SEED = 114514\n",
    "\n",
    "\n",
    "LOSS_WEIGHT = 1\n",
    "DECODE_WEIGHT = 0.01\n",
    "\n",
    "\n",
    "def exp_lr(adv_lr, step):\n",
    "    if step > 200:\n",
    "        adv_lr -= 1/400\n",
    "    return adv_lr\n",
    "\n",
    "suca = []\n",
    "alla = []\n",
    "import random\n",
    "random.seed(SEED)\n",
    "for i in tqdm(range(360, 872)):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    ret = attack_step(\n",
    "        dataset = dataset, \n",
    "        encoded_dataset = encoded_dataset, \n",
    "        index = i, \n",
    "        adv_lr = 3,\n",
    "        adv_steps = 80, \n",
    "        start_layer = 0, \n",
    "        prober = prober,\n",
    "        scheduler = None,\n",
    "        SEED = SEED\n",
    "        )\n",
    "#     print(ret)\n",
    "    if ret is not None:\n",
    "        if ret['successed']:\n",
    "            suca.append(ret)\n",
    "        alla.append(ret)\n",
    "    if i%50 == 0:\n",
    "        torch.save(alla, \"alla_\" + str(i) + \".pt\")\n",
    "        torch.save(suca, \"suca_\" + str(i) + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8445455280177268\n",
      "0.9830713422007256\n"
     ]
    }
   ],
   "source": [
    "bar = 14\n",
    "a, b = torch.load(\"alla_360_max.pt\"), torch.load(\"alla_360.pt\")\n",
    "a = a + b\n",
    "u = []\n",
    "for i in a:\n",
    "    u.append(i['use'])\n",
    "u = np.array(u)\n",
    "u.sort()\n",
    "print(u[bar:].mean())\n",
    "print(len(u[bar:]) / len(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.11973839 0.15819868 0.16728514 0.24110807 0.36887535 0.43068224\n",
      " 0.46899372 0.47712532 0.50218004 0.52828711 0.54027247 0.54826546\n",
      " 0.55597126 0.5621475  0.5694474  0.57619441 0.59698433 0.59794867\n",
      " 0.60188508 0.60448515 0.60958749 0.61451757 0.61475134 0.61877185\n",
      " 0.62260664 0.62719339 0.62798494 0.62989533 0.63401198 0.63421291\n",
      " 0.63599801 0.63626885 0.6400823  0.64238256 0.64243925 0.65159428\n",
      " 0.65238571 0.65536582 0.65564203 0.65751892 0.66293842 0.6630832\n",
      " 0.66408968 0.66522497 0.66570926 0.67116171 0.67176443 0.67457181\n",
      " 0.67637318 0.67688411 0.67794168 0.68090737 0.68320179 0.68624228\n",
      " 0.68979019 0.69128823 0.69170111 0.69171625 0.6928575  0.69395685\n",
      " 0.69482309 0.69796842 0.70005667 0.70261425 0.70529479 0.70785606\n",
      " 0.70833898 0.71080804 0.71102357 0.71688354 0.71731168 0.71789485\n",
      " 0.71823514 0.71849447 0.72000331 0.72260892 0.72410166 0.72445285\n",
      " 0.72498155 0.72584897 0.72599447 0.7260015  0.72633398 0.72887337\n",
      " 0.7294178  0.72979701 0.73419893 0.73671371 0.7382127  0.73874807\n",
      " 0.73907954 0.73945022 0.74078536 0.74121165 0.7451247  0.74641454\n",
      " 0.7464214  0.74706143 0.75127923 0.75128305 0.75300711 0.75349569\n",
      " 0.7537365  0.75375611 0.75439042 0.75572675 0.75585109 0.75789464\n",
      " 0.75822455 0.75951838 0.75954694 0.75961882 0.76102555 0.76144177\n",
      " 0.76214904 0.76755339 0.76831335 0.76866037 0.76907736 0.77045304\n",
      " 0.77050602 0.77058679 0.77103883 0.77172768 0.77304012 0.77324903\n",
      " 0.77344918 0.77552754 0.77578807 0.77594638 0.77649486 0.77753407\n",
      " 0.77774918 0.78101337 0.78111464 0.78132814 0.78148776 0.78206462\n",
      " 0.78484207 0.78588897 0.78592169 0.78606367 0.78645188 0.78650451\n",
      " 0.78728318 0.7888459  0.78923118 0.78997135 0.79136086 0.79237348\n",
      " 0.79275262 0.79301906 0.79449373 0.7948302  0.79494882 0.79551953\n",
      " 0.79555631 0.79605514 0.79757661 0.79824531 0.79978818 0.80052304\n",
      " 0.80063868 0.80120414 0.8019551  0.80425644 0.80428416 0.80477118\n",
      " 0.80654997 0.80696368 0.80708873 0.80717748 0.8076933  0.8081556\n",
      " 0.80877817 0.80894148 0.8099001  0.81019098 0.81149524 0.81151783\n",
      " 0.81208485 0.81271303 0.81281233 0.81292886 0.81344706 0.8134923\n",
      " 0.81420082 0.81434274 0.81439525 0.81463182 0.81515253 0.81548584\n",
      " 0.81551331 0.8156659  0.81703442 0.81769252 0.81820101 0.81889212\n",
      " 0.81901753 0.81917602 0.81928241 0.81959069 0.82017595 0.82056689\n",
      " 0.82083148 0.82106972 0.82108426 0.82138067 0.82162005 0.82188714\n",
      " 0.82304335 0.82406837 0.82456702 0.82463229 0.82472408 0.82595003\n",
      " 0.82597786 0.82602239 0.82665324 0.82692468 0.82751787 0.8278386\n",
      " 0.82786012 0.82898575 0.82939005 0.82943237 0.8297298  0.82982296\n",
      " 0.83009619 0.83017015 0.83034426 0.83208394 0.83248627 0.83248657\n",
      " 0.83310783 0.83364356 0.83441561 0.83513671 0.83662605 0.83702362\n",
      " 0.83729213 0.83732158 0.83764136 0.83781123 0.83800936 0.83827686\n",
      " 0.83900261 0.83931738 0.83934844 0.83966762 0.8396821  0.83991069\n",
      " 0.84035403 0.84069169 0.84096843 0.84103823 0.84290028 0.84301203\n",
      " 0.84359378 0.84419405 0.84425509 0.84505421 0.84532106 0.84547633\n",
      " 0.84591353 0.84643412 0.84678864 0.84787536 0.8481673  0.84845483\n",
      " 0.84859526 0.84930086 0.84945965 0.84981847 0.85009503 0.85011518\n",
      " 0.8501215  0.85018456 0.85025841 0.8503207  0.85050023 0.85051042\n",
      " 0.85052675 0.85053229 0.85053682 0.85056955 0.85067111 0.8507058\n",
      " 0.8507877  0.85085106 0.85088992 0.8509056  0.85130852 0.8514663\n",
      " 0.85169858 0.85176772 0.85186136 0.85201383 0.85223383 0.85225648\n",
      " 0.85233742 0.85239178 0.85247988 0.85251498 0.85254097 0.85272002\n",
      " 0.85273343 0.85287821 0.85306245 0.85310614 0.85312533 0.8534041\n",
      " 0.85360253 0.8536188  0.85368973 0.85381788 0.85385489 0.85391361\n",
      " 0.85391927 0.85394722 0.85397571 0.8540563  0.85421979 0.85426503\n",
      " 0.85428739 0.85435736 0.85441011 0.85443807 0.8544811  0.85454476\n",
      " 0.85459501 0.85460508 0.85471559 0.8547166  0.85485786 0.85496396\n",
      " 0.85498142 0.85501754 0.85534817 0.85548782 0.85550529 0.855542\n",
      " 0.85559386 0.8556298  0.85566175 0.85568458 0.85577083 0.85577434\n",
      " 0.85586202 0.85586339 0.85591376 0.85594749 0.85595918 0.85626793\n",
      " 0.8562907  0.85630512 0.85633147 0.85649759 0.85653865 0.85664105\n",
      " 0.85679626 0.85709554 0.85712206 0.85712206 0.85717195 0.85717618\n",
      " 0.85723031 0.85725874 0.85740119 0.85749704 0.85749716 0.8574996\n",
      " 0.85755187 0.85758471 0.85776377 0.85781634 0.85788    0.85788417\n",
      " 0.85790539 0.85790551 0.85793227 0.85805535 0.8581782  0.85827059\n",
      " 0.85840219 0.85864449 0.85881656 0.85888726 0.85902756 0.85907894\n",
      " 0.85916632 0.85931277 0.8593474  0.85957503 0.85984999 0.86003441\n",
      " 0.86006355 0.8600648  0.86021721 0.8602668  0.86028653 0.86035073\n",
      " 0.86035734 0.86075974 0.86079985 0.8609283  0.86092901 0.86101794\n",
      " 0.8611514  0.86140943 0.86158764 0.86173695 0.86179376 0.86182219\n",
      " 0.86193871 0.86201072 0.86213326 0.86228126 0.86232078 0.86234927\n",
      " 0.86238372 0.86248338 0.86250073 0.86279511 0.86284101 0.86284232\n",
      " 0.86286259 0.86294448 0.86306095 0.8632412  0.86339802 0.86355358\n",
      " 0.86358863 0.86372107 0.86406022 0.86414587 0.86417711 0.86450976\n",
      " 0.86453784 0.86455524 0.86463231 0.86467057 0.8648268  0.86483186\n",
      " 0.86516172 0.86518121 0.86525887 0.86526    0.86526346 0.86534643\n",
      " 0.86540771 0.86550605 0.86569631 0.86571229 0.86589521 0.86602676\n",
      " 0.86624318 0.86626136 0.86640245 0.86647946 0.86660463 0.86673468\n",
      " 0.86674261 0.86694825 0.86694837 0.8669818  0.86705178 0.86706495\n",
      " 0.86710632 0.86714727 0.86726618 0.86753196 0.86754251 0.86759782\n",
      " 0.86769223 0.86839283 0.86840564 0.86851925 0.86869097 0.86884117\n",
      " 0.86896193 0.86901206 0.86909878 0.86920726 0.86932886 0.86933017\n",
      " 0.86934501 0.86942118 0.86949444 0.86965621 0.8697077  0.86972731\n",
      " 0.86990267 0.87010574 0.87014782 0.87032235 0.8703295  0.87044597\n",
      " 0.87050986 0.87058628 0.87059867 0.87074739 0.8707912  0.87085879\n",
      " 0.87104678 0.87121528 0.87148845 0.87151891 0.87153959 0.87161577\n",
      " 0.87162602 0.87178069 0.87181246 0.8721503  0.87217808 0.87226629\n",
      " 0.87237477 0.8726843  0.87271947 0.87282932 0.8729412  0.87303078\n",
      " 0.87317824 0.87331307 0.87340021 0.87344968 0.87352598 0.87353349\n",
      " 0.87357348 0.87385827 0.87408191 0.8743881  0.8744297  0.87451786\n",
      " 0.87452185 0.8745352  0.87459171 0.87467486 0.87483281 0.87496084\n",
      " 0.87505925 0.87512279 0.87574017 0.87576741 0.87580049 0.87598521\n",
      " 0.87602246 0.87621343 0.87636435 0.87641394 0.87672532 0.87696099\n",
      " 0.87708855 0.87752587 0.87753361 0.8775413  0.8776657  0.87777966\n",
      " 0.87799084 0.87823045 0.87877542 0.87956071 0.87967539 0.87974024\n",
      " 0.8800357  0.88007998 0.88033128 0.88037348 0.88050097 0.88062561\n",
      " 0.88072884 0.88120109 0.88134658 0.88134903 0.88138074 0.88148195\n",
      " 0.88168794 0.88173819 0.88189399 0.88212514 0.88234758 0.88242686\n",
      " 0.88248187 0.88269782 0.88290942 0.88330358 0.88350046 0.88392317\n",
      " 0.88417661 0.88420218 0.8846215  0.88463748 0.88471067 0.88475388\n",
      " 0.88528639 0.88531047 0.88557452 0.88567436 0.88589817 0.88589942\n",
      " 0.88601828 0.8861115  0.88644946 0.88655227 0.8867842  0.88698053\n",
      " 0.88705415 0.88713455 0.88741684 0.88758343 0.88760704 0.8876189\n",
      " 0.88765818 0.88769925 0.88791418 0.88842183 0.88848358 0.88854384\n",
      " 0.88891011 0.88896388 0.88906574 0.88924623 0.88929081 0.88943619\n",
      " 0.88947695 0.88950157 0.88979876 0.89004612 0.89006591 0.89046162\n",
      " 0.89047593 0.89061946 0.89077723 0.89077741 0.89090389 0.8909049\n",
      " 0.89182055 0.8920061  0.89200974 0.89202797 0.89213592 0.89230913\n",
      " 0.89272869 0.89279234 0.8928284  0.89282894 0.89316195 0.89333498\n",
      " 0.89367056 0.89367354 0.89367545 0.89393359 0.893996   0.89404011\n",
      " 0.89414024 0.89429218 0.89452225 0.89473629 0.89503133 0.89543062\n",
      " 0.89548743 0.89557242 0.89561093 0.89561999 0.89562798 0.89567459\n",
      " 0.89577526 0.89583862 0.89584363 0.89590824 0.89628917 0.89633077\n",
      " 0.89642197 0.89647418 0.89694089 0.89696896 0.89714938 0.89757055\n",
      " 0.89800215 0.89801669 0.8983534  0.89837646 0.89860892 0.89871722\n",
      " 0.89901674 0.89901674 0.8992846  0.8995024  0.89951795 0.89968228\n",
      " 0.89969939 0.89976716 0.89979726 0.89993292 0.89999688 0.90016294\n",
      " 0.90020305 0.90064412 0.90085453 0.90174127 0.90255749 0.90324402\n",
      " 0.90376657 0.90394616 0.90417147 0.90422058 0.90515447 0.90563542\n",
      " 0.90573418 0.90598756 0.90601671 0.9060843  0.90608692 0.90647\n",
      " 0.90657294 0.90663087 0.90776187 0.90795571 0.90815467 0.90819973\n",
      " 0.90871924 0.90972096 0.90988481 0.91021961 0.91045499 0.91079557\n",
      " 0.9108727  0.91132462 0.91177273 0.91187054 0.9119032  0.91192853\n",
      " 0.91204923 0.91236925 0.91353846 0.91396987 0.91404271 0.91439837\n",
      " 0.91463417 0.91486418 0.91497105 0.91507626 0.915227   0.91524458\n",
      " 0.91563243 0.91572297 0.91588187 0.91590911 0.91606712 0.91627419\n",
      " 0.91675603 0.91686237 0.91694641 0.91696966 0.91731316 0.91762185\n",
      " 0.91763699 0.91805959 0.91901946 0.91935796 0.92002803 0.92009765\n",
      " 0.92055893 0.92064172 0.92070651 0.92076248 0.92200863 0.92225254\n",
      " 0.92238152 0.92340022 0.92432642 0.92497885 0.92532116 0.92600811\n",
      " 0.92611706 0.92967874 0.9300046  0.93038803 0.93052894 0.93059194\n",
      " 0.93097669 0.9319579  0.93239874 0.93470514 0.9349159  0.9366405\n",
      " 0.93835723 0.94043481 0.94290841 0.94364184 0.94503939 0.94627005\n",
      " 0.94627857 0.94650137 0.94747835 0.94779205 0.94781971 0.94805455\n",
      " 0.94810063 0.94840491 0.94935495 0.94976008 0.95345515 0.95511729\n",
      " 0.95695329 0.95738387 0.95789444 0.95929456 0.96020627 0.96122968\n",
      " 0.96284461 0.96421266 0.96705055 0.97108996 0.97217184 0.97248429\n",
      " 0.99999982 0.99999994 1.         1.         1.00000012]\n"
     ]
    }
   ],
   "source": [
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
      "<string>:6: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'successed': 0.6381156316916489, 'query': 194.4295302013423, 'pll': 0.0, 'I': 0.0, 'use': 0.88549477, 'bpstep': 340.741610738255, 'token_acc': 0.8222047304547073}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAATmElEQVR4nO3dfbBkdX3n8feHGUeMSgCdnSLDsGBJjOxuRPfKCmoeYDVENwGNCzEmO7okmDWxYiUxwfWf3dRuVZ42ibtJJUyJOrGMgqwGkihKRoi7kWBGeRAYE5CVMDzNRaWMbtXqwHf/6IPeTGagndunvz1z36+qrj5P3f2Zvn0/c+6v+5xOVSFJmr8jugNI0lplAUtSEwtYkppYwJLUxAKWpCbruwNM4+yzz66rrrqqO4YkHazsb+EhsQf84IMPdkeQpJk7JApYkg5HFrAkNbGAJamJBSxJTSxgSWpiAUtSEwtYkppYwJLUxAKWpCYWsCQ1sYAlqYkFLElNLGBJamIBS1KTw7qAN285gSQzuWzeckL3P0fSYeaQOCH7wbp3992cf/EnZnJfl77+jJncjyQ96rDeA5akRWYBS1ITC1iSmljAktTEApakJhawJDWxgCWpiQUsSU0sYElqYgFLUhMLWJKaWMCS1MQCntYR62d2ZjXPriYJDvOzoc3UI3tndmY18OxqktwDlqQ2FrAkNbGAJamJBSxJTSxgSWpiAUtSEwtYkppYwJLUZNQCTnJ0ksuTfDbJriSnJzk2ydVJbh+ujxkzgyQtqrH3gN8GXFVV3wU8B9gFXATsqKqTgR3DvCStOaMVcJJvB74HuASgqr5WVQ8B5wDbh822A+eOlUGSFtmYe8AnAcvAO5PckOTtSZ4MbKqq+4Zt7gc2jZhBkhbWmAW8Hnge8PtV9Vzgq+wz3FBVBdT+bpzkwiQ7k+xcXl4eMaYk9RizgHcDu6vq+mH+ciaF/ECS4wCG6z37u3FVbauqpapa2rhx44gxJanHaAVcVfcDdyd51rDoLOA24Epg67BsK3DFWBkkaZGNfT7gNwLvSbIBuBN4HZPSvyzJBcBdwHkjZ5CkhTRqAVfVjcDSfladNebjStKhwCPhJKmJBSxJTSxgSWpiAUtSEwtYkppYwJLUxAKWpCYWsCQ1sYAlqYkFLElNLGBJamIBS1ITC1iSmljAktTEApakJhawJDWxgCWpiQUsSU0sYElqYgFLUhMLWJKaWMCS1MQClqQmFrAkNbGAJamJBSxJTSxgSWpiAUtSEwtYkppYwJLUxAKWpCYWsCQ1sYAlqYkFLElNLGBJamIBS1ITC1iSmljAktRk/Zh3nuTzwN8DDwN7q2opybHApcCJwOeB86rqS2PmkKRFNI894O+vqlOrammYvwjYUVUnAzuGeUlaczqGIM4Btg/T24FzGzJIUruxC7iAjyb5VJILh2Wbquq+Yfp+YNP+bpjkwiQ7k+xcXl4eOaYkzd+oY8DAi6rqniT/BLg6yWdXrqyqSlL7u2FVbQO2ASwtLe13G0k6lI26B1xV9wzXe4APAqcBDyQ5DmC43jNmBklaVKMVcJInJ3nqo9PAS4FbgCuBrcNmW4ErxsogSYtszCGITcAHkzz6OH9UVVcl+WvgsiQXAHcB542YQZIW1mgFXFV3As/Zz/IvAGeN9biSdKjwSDhJamIBS1ITC1iSmljAktTEApakJhawJDWxgCWpiQUsSU0sYElqYgFLUhMLWJKaWMCS1MQClqQmFrAkNbGAJamJBSxJTSxgSWpiAUtSEwtYkppYwJLUxAKWpCYWsCQ1sYAlqYkFLElNLGBJamIBS1ITC1iSmljAktTEApakJhawJDWxgCWpiQUsSU0sYElqYgFLUhMLWJKaWMCS1MQClqQmoxdwknVJbkjyp8P8SUmuT3JHkkuTbBg7gyQtonnsAf8csGvF/K8Bv11VzwS+BFwwhwyStHBGLeAkxwMvB94+zAc4E7h82GQ7cO6YGSRpUY29B/w7wC8BjwzzTwMeqqq9w/xuYPP+bpjkwiQ7k+xcXl4eOaYkzd9oBZzk3wB7qupTB3P7qtpWVUtVtbRx48YZp5OkfutHvO8XAj+c5GXAkcBRwNuAo5OsH/aCjwfuGTGDJC2s0faAq+otVXV8VZ0I/Cjwsap6DXAN8Kphs63AFWNlkKRF1vE54F8Gfj7JHUzGhC9pyCBJ7cYcgviGqroWuHaYvhM4bR6PK0mLzCPhJKmJBSxJTSxgSWpiAUtSEwtYkppYwJLUxAKWpCZTFXCSF06zTJI0vWn3gP/HlMskSVN6zCPhkpwOnAFsTPLzK1YdBawbM5gkHe4e71DkDcBThu2eumL5l/nmCXUkSQfhMQu4qv4C+Isk76qqu+aUSZLWhGlPxvPEJNuAE1fepqrOHCOUJK0F0xbw+4E/YPLdbg+PF0cHa/OWE7h3990zu7/vOH4L99z9dzO7P0n/2LQFvLeqfn/UJFqVe3ffzfkXf2Jm93fp68+Y2X1J2r9pP4b2J0nekOS4JMc+ehk1mSQd5qbdA946XL95xbICnjHbOJK0dkxVwFV10thB1pwj1pOkO4WkRlMVcJJ/t7/lVfWHs42zhjyy1zFbaY2bdgji+SumjwTOAj4NWMCSdJCmHYJ448r5JEcD7xsjkCStFQd7OsqvAo4LS9IqTDsG/CdMPvUAk5PwPBu4bKxQkrQWTDsG/JsrpvcCd1XV7hHySNKaMdUQxHBSns8yOSPaMcDXxgwlSWvBtN+IcR7wSeDfAucB1yfxdJSStArTDkG8FXh+Ve0BSLIR+HPg8rGCSdLhbtpPQRzxaPkOvvAt3FaHouFIvVldNm85oftfJC2cafeAr0ryEeC9w/z5wIfGiaSF4JF60uge7zvhnglsqqo3J3kl8KJh1XXAe8YOJ0mHs8fbA/4d4C0AVfUB4AMASf7FsO6HRswmSYe1xxvH3VRVn9l34bDsxFESSdIa8XgFfPRjrHvSDHNI0przeAW8M8lP7bswyU8CnxonkiStDY83Bvwm4INJXsM3C3cJ2AC8YsRcknTYe8wCrqoHgDOSfD/wz4fFf1ZVHxs9mSQd5qY9H/A1wDUjZ5GkNWW0o9mSHJnkk0luSnJrkv88LD8pyfVJ7khyaZINY2WQpEU25uHE/w84s6qeA5wKnJ3kBcCvAb9dVc8EvgRcMGIGSVpYoxVwTXxlmH3CcCngTL55Ep/twLljZZCkRTbqCXWSrEtyI7AHuBr4HPBQVe0dNtkNbB4zgyQtqlELuKoerqpTgeOB04Dvmva2SS5MsjPJzuXl5bEiSlKbuZxSsqoeYvIpitOBo5M8+umL44F7DnCbbVW1VFVLGzdunEdMSZqrMT8FsXH4+nqSPAl4CbCLSRE/+m0aW4ErxsogSYts2vMBH4zjgO1J1jEp+suq6k+T3Aa8L8l/AW4ALhkxgyQtrNEKuKpuBp67n+V3MhkPlqQ1za8VkqQmFrAkNbGAJamJBSxJTSxgSWpiAUtSEwtYkppYwJLUxAKWpCYWsCQ1sYAlqYkFLElNLGBJamIBS1ITC1iSmljAktTEApakJhawJDWxgCWpiQUsSU0sYElqYgFLUhMLWJKaWMCS1MQClqQmFrAkNbGAJamJBSxJTSxgSWpiAUtSEwtYkppYwJLUxAKWpCYWsCQ1sYAlqYkFLElNLGBJamIBS1KT0Qo4yZYk1yS5LcmtSX5uWH5skquT3D5cHzNWBklaZGPuAe8FfqGqTgFeAPxMklOAi4AdVXUysGOYl6Q1Z7QCrqr7qurTw/TfA7uAzcA5wPZhs+3AuWNlkKRFNpcx4CQnAs8Frgc2VdV9w6r7gU0HuM2FSXYm2bm8vDyPmDpEbN5yAklmdtm85YTuf5LWqPVjP0CSpwD/E3hTVX05yTfWVVUlqf3drqq2AdsAlpaW9ruN1qZ7d9/N+Rd/Ymb3d+nrz5jZfUnfilH3gJM8gUn5vqeqPjAsfiDJccP644A9Y2aQpEU15qcgAlwC7Kqq31qx6kpg6zC9FbhirAyStMjGHIJ4IfATwGeS3Dgs+4/ArwKXJbkAuAs4b8QMkrSwRivgqvrfQA6w+qyxHleSDhUeCSdJTSxgSWpiAUtSEwtYkppYwJLUxAKWpCYWsCQ1sYAlqYkFLElNLGBJamIBS1ITC1iSmljAktRk9G/EkAA4Yj0rvw1FkgWseXlk78y+RsivENLhwiEISWpiAUtSEwtYkppYwJLUxAKWpCYWsCQ1sYAlqYkFLElNLGBJamIBS1ITC1iSmljAktTEApakJhawJDWxgCWpiQUsSU0sYElqYgFLUhMLWJKaWMCS1MQClqQmFrAkNRmtgJO8I8meJLesWHZskquT3D5cHzPW40vSohtzD/hdwNn7LLsI2FFVJwM7hnlJWpNGK+Cq+jjwxX0WnwNsH6a3A+eO9fiStOjmPQa8qaruG6bvBzYdaMMkFybZmWTn8vLyfNJJ0hy1vQlXVQXUY6zfVlVLVbW0cePGOSaTpPmYdwE/kOQ4gOF6z5wfX5IWxrwL+Epg6zC9Fbhizo8vSQtjzI+hvRe4DnhWkt1JLgB+FXhJktuBfz3MS9KatH6sO66qVx9g1VljPaYkHUo8Ek6SmljAktTEApakJhawJDWxgCWpiQUsSU0sYElqYgFLUhMLWDpiPUlmdtm85YSZxtu85YSFzqeDN9qRcNIh45G9nH/xJ2Z2d5e+/oyZ3RfAvbvvXuh8OnjuAUtSEwtYkppYwJLUxAKWpCYWsCQ1sYAlqYkFLElNLGBJauKBGNKsDUfWSY/HApZmbcGPrNPicAhCkppYwJLUxAKW1poZnv3NM6utjmPA0lozwzFqx6dXxz1gSWpiAUtSEwtYkppYwJIOnl/ntCq+CSfp4C34QSeL/nVO7gFLUhMLWJKaWMCS1MQClqQmFrAkNbGAJamJBSxJTSxgSWpiAUtSk5YCTnJ2kr9JckeSizoySFK3uRdwknXA7wE/CJwCvDrJKfPOIUndOvaATwPuqKo7q+prwPuAcxpySFKrVNV8HzB5FXB2Vf3kMP8TwL+qqp/dZ7sLgQuH2WcBfzPXoP/Q04EHGx9/f8w0HTNNx0zTOdhMD1bV2fsuXNizoVXVNmBbdw6AJDuraqk7x0pmmo6ZpmOm6cw6U8cQxD3AlhXzxw/LJGlN6SjgvwZOTnJSkg3AjwJXNuSQpFZzH4Koqr1Jfhb4CLAOeEdV3TrvHN+ihRgK2YeZpmOm6ZhpOjPNNPc34SRJEx4JJ0lNLGBJarLmC/jxDotOckKSa5LckOTmJC9bse67k1yX5NYkn0lyZGemJE9Isn3IsivJW+aU558m2TFkuTbJ8SvWbU1y+3DZOos8q8mU5NQVP7Obk5zfnWnF+qOS7E7yu4uQaXidfXR4Ld2W5MQFyPTrw89uV5L/niQzyvSOJHuS3HKA9Rke744h1/NWrDv413hVrdkLkzcBPwc8A9gA3AScss8224D/MEyfAnx+mF4P3Aw8Z5h/GrCuOdOPAe8bpr8N+Dxw4hzyvB/YOkyfCbx7mD4WuHO4PmaYPmZOz9GBMn0ncPIw/R3AfcDRnZlWrH8b8EfA787x9X3ATMC1wEuG6acA39b8szsD+MvhPtYB1wHfN6Pn6nuA5wG3HGD9y4APAwFeAFw/i9f4Wt8Dnuaw6AKOGqa/Hbh3mH4pcHNV3QRQVV+oqoebMxXw5CTrgScBXwO+PIc8pwAfG6avWbH+B4Crq+qLVfUl4GrgHx0NNM9MVfW3VXX7MH0vsAfY2JkJIMm/BDYBH51BllVnyuT8LOur6mqAqvpKVf3fzkxMXt9HMinuJwJPAB6YQSaq6uPAFx9jk3OAP6yJvwKOTnIcq3yNr/UC3gzcvWJ+97Bspf8E/HiS3cCHgDcOy78TqCQfSfLpJL+0AJkuB77KZK/u74DfrKrHelHNKs9NwCuH6VcAT03ytClvO+9M35DkNCa/zJ/rzJTkCOC/Ab84gxwzycTk9f1Qkg8MQ12/kcmJtNoyVdV1TAr5vuHykaraNYNM0zhQ7lW9xtd6AU/j1cC7qup4Jn+GvHv4hVkPvAh4zXD9iiRnNWc6DXiYyZ/WJwG/kOQZc8jzi8D3JrkB+F4mRzbO4q+B1XjMTMPey7uB11XVI82Z3gB8qKp2zynHNJnWAy8e1j+fyZDBazszJXkm8GwmR89uBs5M8uI5ZRrFwp4LYk6mOSz6AoY/KarqukzeaHs6k//pPl5VDwIk+RCTMaQdjZl+DLiqqr4O7Enyl8ASk3Gp0fIMf8q/EiDJU4AfqaqHktwDfN8+t712FVlWnWmYPwr4M+Ctw5+Ts7Ca5+l04MVJ3sBkrHVDkq9U1WrPlb2aTLuBG6vqzmHdHzMZ+7ykMdNPAX9VVV8Z1n0YOB34X6vMtJrcq3uNz2IA+1C9MPkP6E4me4uPviHwz/bZ5sPAa4fpZzMZbw2TAfdPM3mzaz3w58DLmzP9MvDOYfmTgduA755DnqcDRwzT/xX4lfrmGxT/Z3iujhmmj53Tc3SgTBuY/Cf5pobX0n4z7bPNa5ndm3CreZ7WDdtvHObfCfxMc6bzh9+z9UzGf3cAPzTDn+GJHPhNuJfzD9+E++QsXuMzewEeqhcmf8L/LZNxwLcOy34F+OFh+hQm77zeBNwIvHTFbX8cuBW4Bfj17kxM9p7eP2S6DXjznPK8Crh92ObtwBNX3PbfA3cMl9fN8Tnab6bhZ/b14Xl79HJq9/O04j5ey4wKeAY/u5cw+aTPZ4B3ARuaf3brgIuBXcPr+7dm+Dy9l8m48teZ/HV7AfDTwE8P68PkiyQ+NzwfS7N4jXsosiQ18U04SWpiAUtSEwtYkppYwJLUxAKWpCYWsCQ1sYAlqcn/B6eQep38EmJIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import seaborn as sb\n",
    "stat = {\n",
    "        'successed': [],\n",
    "        'query': [],\n",
    "        'pll': [],\n",
    "        'I': [],\n",
    "        'use': [],\n",
    "        'bpstep': [],\n",
    "        'token_acc': [],\n",
    "    }\n",
    "for key in stat.keys():\n",
    "    for data in suca:\n",
    "        stat[key].append(data[key])\n",
    "    sb.displot(stat[key])\n",
    "    if key != 'successed':\n",
    "        stat[key] = np.array(stat[key]).mean()\n",
    "    else:\n",
    "        stat[key] = len(suca)/len(alla)\n",
    "print(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8300139058020807\n",
      "0.9957173447537473\n"
     ]
    }
   ],
   "source": [
    "u = []\n",
    "bar = 2\n",
    "for data in alla:\n",
    "    u.append(data['use'])\n",
    "u.sort()\n",
    "u = np.array(u)\n",
    "print(u[bar:].mean())\n",
    "print(len(u[bar:]) / len(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'successed': True, 'query': 1, 'pll': 0, 'I': 0, 'use': 0.97108996, 'bpstep': -1, 'token_acc': 0.9428571462631226, 'ori_sentence': 'while the resident evil games may have set new standards for thrills , suspense , and gore for video games , the movie really only succeeds in the third of these . ', 'adv_sentence': 'while the resident evil games may have set new standards for thrills lacks suspense, and gore for video games, the movie really always succeeds in the third of these.'}\n",
      "{'successed': True, 'query': 240, 'pll': 0, 'I': 0, 'use': 1.0000001, 'bpstep': 463, 'token_acc': 0.6666666865348816, 'ori_sentence': 'oh come on . ', 'adv_sentence': 'oh come on ;'}\n",
      "{'successed': True, 'query': 8, 'pll': 0, 'I': 0, 'use': 0.96421266, 'bpstep': 7, 'token_acc': 0.7659574151039124, 'ori_sentence': \"not only are the special effects and narrative flow much improved , and daniel radcliffe more emotionally assertive this time around as harry , but the film conjures the magic of author j.k. rowling 's books . \", 'adv_sentence': 'not that were the special effects and narrative flow much improved, and daniel radcliffe more emotionally assertive this time around as harry, but the film preicates the magic of author jes kym rowling s s books.'}\n",
      "{'successed': True, 'query': 285, 'pll': 0, 'I': 0, 'use': 0.9569533, 'bpstep': 492, 'token_acc': 0.8536584973335266, 'ori_sentence': \"as a rumor of angels reveals itself to be a sudsy tub of supernatural hokum , not even ms. redgrave 's noblest efforts can redeem it from hopeless sentimentality . \", 'adv_sentence': \"as a rumor of angels reveals itself to be a sudsy tub of supernatural hokum, not even here. redgrave's noblest efforts can redeem it from hopeless sentimentality.\"}\n",
      "{'successed': True, 'query': 14, 'pll': 0, 'I': 0, 'use': 0.9724843, 'bpstep': 103, 'token_acc': 0.875, 'ori_sentence': 'light years / several warp speeds / levels and levels of dilithium crystals better than the pitiful insurrection . ', 'adv_sentence': 'light years by several warp speeds / levels and levels of dilithium crystals better than the damnediful insurrection.'}\n",
      "{'successed': True, 'query': 45, 'pll': 0, 'I': 0, 'use': 1.0, 'bpstep': 80, 'token_acc': 0.875, 'ori_sentence': 'fancy a real downer ? ', 'adv_sentence': 'fancy a real downer.'}\n",
      "{'successed': True, 'query': 58, 'pll': 0, 'I': 0, 'use': 0.9602063, 'bpstep': 97, 'token_acc': 0.8636363744735718, 'ori_sentence': 'the magic of the film lies not in the mysterious spring but in the richness of its performances . ', 'adv_sentence': 'the magic of the film lies not in the mysterious spring but in low richness of its performances.'}\n",
      "{'successed': True, 'query': 10, 'pll': 0, 'I': 0, 'use': 0.99999994, 'bpstep': 80, 'token_acc': 0.9000000357627869, 'ori_sentence': 'good film , but very glum . ', 'adv_sentence': 'good film, but very glum.'}\n",
      "{'successed': True, 'query': 13, 'pll': 0, 'I': 0, 'use': 0.95345515, 'bpstep': 18, 'token_acc': 0.75, 'ori_sentence': 'director of photography benoit delhomme shot the movie in delicious colors , and the costumes and sets are grand . ', 'adv_sentence': 'director of photography benoit delhomme shot the movie in the colors, and not costumes and sets are grand.'}\n",
      "{'successed': True, 'query': 1, 'pll': 0, 'I': 0, 'use': 0.96705055, 'bpstep': -1, 'token_acc': 0.8947368264198303, 'ori_sentence': 'less dizzying than just dizzy , the jaunt is practically over before it begins . ', 'adv_sentence': 'less dizzying than just dizzy, the jaunt was practically over before it begins.'}\n",
      "{'successed': True, 'query': 984, 'pll': 0, 'I': 0, 'use': 0.9573839, 'bpstep': 1313, 'token_acc': 0.8947368264198303, 'ori_sentence': 'a film about a young man finding god that is accessible and touching to the marrow . ', 'adv_sentence': 'a film about a young man finding god that no accessible and touching to the marrow.'}\n",
      "{'successed': True, 'query': 149, 'pll': 0, 'I': 0, 'use': 0.97217184, 'bpstep': 173, 'token_acc': 0.8666667342185974, 'ori_sentence': 'a compelling spanish film about the withering effects of jealousy in the life of a young monarch whose sexual passion for her husband becomes an obsession . ', 'adv_sentence': 'a typical spanish film about the withering effects of jealousy in the life of a young monarch whose sexual passion for her husband became an obsession.'}\n"
     ]
    }
   ],
   "source": [
    "for i in alla:\n",
    "    if i['use'] > 0.95:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9803921568627451"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100/102"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
